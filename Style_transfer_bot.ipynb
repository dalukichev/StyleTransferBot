{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style_transfer_bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "276_J7j5NcYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7175552-bdb3-4d00-c236-0a36a4ea9a73"
      },
      "source": [
        "!pip install python-telegram-bot\n",
        "!pip install -U ipykernel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.7/dist-packages (13.13)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2022.1)\n",
            "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (4.2.2)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (6.2)\n",
            "Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (3.6.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2022.6.15)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (57.4.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (6.15.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.4.8)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (6.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (0.1.3)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (7.3.4)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel) (1.5.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipykernel) (21.3)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (23.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (57.4.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.30)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel) (2.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (4.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipykernel) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUPu1DpEO1iL"
      },
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from scipy import misc\n",
        "import copy\n",
        "import numpy as np \n",
        "\n",
        "import os\n",
        "from telegram.ext import Updater, MessageHandler, Filters, CommandHandler, ConversationHandler, CallbackQueryHandler\n",
        "from telegram.ext.dispatcher import run_async\n",
        "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
        "import logging\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3FQM7wsO_L7"
      },
      "source": [
        "class ContentLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, target, ):\n",
        "        super(ContentLoss, self).__init__()\n",
        "        self.target = target.detach()  \n",
        "        self.loss = F.mse_loss(self.target, self.target)  \n",
        "\n",
        "    def forward(self, input):\n",
        "        self.loss = F.mse_loss(input, self.target)\n",
        "        return input"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHP-xYxePB4L"
      },
      "source": [
        "class StyleLoss(nn.Module):\n",
        "    def __init__(self, target_feature):\n",
        "        super(StyleLoss, self).__init__()\n",
        "        self.target = self.gram_matrix(target_feature).detach()\n",
        "        self.loss = F.mse_loss(self.target, self.target)  \n",
        "\n",
        "    def forward(self, input):\n",
        "        G = self.gram_matrix(input)\n",
        "        self.loss = F.mse_loss(G, self.target)\n",
        "        return input\n",
        "\n",
        "    def gram_matrix(self,input):\n",
        "        batch_size, h, w, f_map_num = input.size()  \n",
        "\n",
        "\n",
        "        features = input.view(batch_size * h, w * f_map_num)  \n",
        "\n",
        "        G = torch.mm(features, features.t()) \n",
        "\n",
        "\n",
        "        return G.div(batch_size * h * w * f_map_num)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TavUrCkjPEVD"
      },
      "source": [
        "class Normalization(nn.Module):\n",
        "    def __init__(self, mean, std):\n",
        "        super(Normalization, self).__init__()\n",
        "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
        "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        return (img - self.mean) / self.std"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXOCsfViPHj8"
      },
      "source": [
        "class StyleTransferModel:\n",
        "    def __init__(self):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
        "        pass\n",
        "\n",
        "\n",
        "    def transfer_style(self, content_img_stream, style_img_stream, num_steps=500,\n",
        "                        style_weight=100000000, content_weight=1):\n",
        "        content_img = self.process_image(content_img_stream)\n",
        "        style_img = self.process_image(style_img_stream)\n",
        "        input_img = content_img.clone().detach()\n",
        "        \"\"\"Run the style transfer.\"\"\"\n",
        "        print('Building the style transfer model..')\n",
        "        model, style_losses, content_losses = self.get_style_model_and_losses(style_img,\n",
        "                                                                         content_img,)\n",
        "        optimizer = self.get_input_optimizer(input_img)\n",
        "\n",
        "        print('Optimizing..')\n",
        "        run = [0]\n",
        "        while run[0] <= num_steps:\n",
        "\n",
        "            def closure():\n",
        "\n",
        "                input_img.data.clamp_(0, 1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                model(input_img)\n",
        "\n",
        "                style_score = 0\n",
        "                content_score = 0\n",
        "\n",
        "                for sl in style_losses:\n",
        "                    style_score += sl.loss\n",
        "                for cl in content_losses:\n",
        "                    content_score += cl.loss\n",
        "\n",
        "                style_score *= style_weight\n",
        "                content_score *= content_weight\n",
        "\n",
        "                loss = style_score + content_score\n",
        "                loss.backward()\n",
        "\n",
        "                run[0] += 1\n",
        "                if run[0] % 50 == 0:\n",
        "                    print(\"run {}:\".format(run))\n",
        "                    print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n",
        "                        style_score.item(), content_score.item()))\n",
        "                    print()\n",
        "\n",
        "                return style_score + content_score\n",
        "\n",
        "            optimizer.step(closure)\n",
        "\n",
        "        input_img.data.clamp_(0, 1)\n",
        "        image = input_img.cpu().clone().detach()\n",
        "        unloader = transforms.ToPILImage()\n",
        "        return unloader(image[0])\n",
        "\n",
        "\n",
        "    def get_input_optimizer(self, input_img):\n",
        "        optimizer = optim.LBFGS([input_img.requires_grad_()]) \n",
        "        return optimizer\n",
        "\n",
        "\n",
        "    def process_image(self, img_stream):\n",
        "        imsize = 720\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(device)\n",
        "        loader = transforms.Compose([\n",
        "            transforms.Resize(imsize),  \n",
        "            transforms.CenterCrop(imsize),\n",
        "            transforms.ToTensor()])  \n",
        "\n",
        "        image = Image.open(img_stream)\n",
        "        image = loader(image).unsqueeze(0)\n",
        "        return image.to(device, torch.float)\n",
        "\n",
        "    def get_style_model_and_losses(self, style_img, content_img):\n",
        "        content_layers = ['conv_4']\n",
        "        style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "        cnn = copy.deepcopy(self.cnn)\n",
        "\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "        normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "        normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
        "\n",
        "        content_losses = []\n",
        "        style_losses = []\n",
        "\n",
        "\n",
        "        model = nn.Sequential(normalization)\n",
        "\n",
        "        i = 0  \n",
        "        for layer in cnn.children():\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                i += 1\n",
        "                name = 'conv_{}'.format(i)\n",
        "            elif isinstance(layer, nn.ReLU):\n",
        "                name = 'relu_{}'.format(i)\n",
        "                layer = nn.ReLU(inplace=False)\n",
        "            elif isinstance(layer, nn.MaxPool2d):\n",
        "                name = 'pool_{}'.format(i)\n",
        "            elif isinstance(layer, nn.BatchNorm2d):\n",
        "                name = 'bn_{}'.format(i)\n",
        "            else:\n",
        "                raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
        "\n",
        "            model.add_module(name, layer)\n",
        "\n",
        "            if name in content_layers:\n",
        "                target = model(content_img).detach()\n",
        "                content_loss = ContentLoss(target)\n",
        "                model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
        "                content_losses.append(content_loss)\n",
        "\n",
        "            if name in style_layers:\n",
        "                target_feature = model(style_img).detach()\n",
        "                style_loss = StyleLoss(target_feature)\n",
        "                model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
        "                style_losses.append(style_loss)\n",
        "\n",
        "\n",
        "        for i in range(len(model) - 1, -1, -1):\n",
        "            if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
        "                break\n",
        "\n",
        "        model = model[:(i + 1)]\n",
        "\n",
        "        return model, style_losses, content_losses"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnp4QlLTmUA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba61c071-aa31-45ec-8e45-5d0faa7a635f"
      },
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pytorch-CycleGAN-and-pix2pix' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogdal6ULmW4j"
      },
      "source": [
        "os.chdir('/content/pytorch-CycleGAN-and-pix2pix/')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqt6a2GVmXYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bc45b4-3880-4ce2-e830-4713be5fb868"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.13.0+cu113)\n",
            "Requirement already satisfied: dominate>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2.6.0)\n",
            "Requirement already satisfied: visdom>=0.1.8.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.1.8.9)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.12.21)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (0.1.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.7.3)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.32)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (1.0.9)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (1.2.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.13)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.1.27)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.6.15)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.7/dist-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnZzFPUDyHU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8baa8a-3f85-49de-8c9f-14b9bf74f6c9"
      },
      "source": [
        "!bash ./scripts/download_cyclegan_model.sh winter2summer_yosemite"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: available models are apple2orange, orange2apple, summer2winter_yosemite, winter2summer_yosemite, horse2zebra, zebra2horse, monet2photo, style_monet, style_cezanne, style_ukiyoe, style_vangogh, sat2map, map2sat, cityscapes_photo2label, cityscapes_label2photo, facades_photo2label, facades_label2photo, iphone2dslr_flower\n",
            "Specified [winter2summer_yosemite]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2022-07-24 15:49:51--  http://efrosgans.eecs.berkeley.edu/cyclegan/pretrained_models/winter2summer_yosemite.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45575747 (43M)\n",
            "Saving to: ‘./checkpoints/winter2summer_yosemite_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/winte 100%[===================>]  43.46M  67.3MB/s    in 0.6s    \n",
            "\n",
            "2022-07-24 15:49:52 (67.3 MB/s) - ‘./checkpoints/winter2summer_yosemite_pretrained/latest_net_G.pth’ saved [45575747/45575747]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro6HaypdMrv5"
      },
      "source": [
        "from io import BytesIO\n",
        "import subprocess\n",
        "import shutil"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NYndXtTM66F",
        "outputId": "1a6744e1-5ff7-4b4d-87c0-5f5a0cde2c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = StyleTransferModel()\n",
        "first_image_file = {}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4OzbQjiA3pp"
      },
      "source": [
        "def send_prediction_on_photo(update, context):\n",
        "    chat_id = update.message.chat_id\n",
        "    print(\"Got image from {}\".format(chat_id))\n",
        "    \n",
        "\n",
        "    image_file = update.message.photo[-1].get_file()\n",
        "\n",
        "    if chat_id in first_image_file:\n",
        "        update.message.reply_text('Принял вторую фотографию. Ожидайте несколько минут')\n",
        "        content_image_stream = BytesIO()\n",
        "        first_image_file[chat_id].download(out=content_image_stream)\n",
        "        del first_image_file[chat_id]\n",
        "\n",
        "        style_image_stream = BytesIO()\n",
        "        image_file.download(out=style_image_stream)\n",
        "        del image_file\n",
        "\n",
        "        output = model.transfer_style(content_image_stream, style_image_stream)\n",
        "\n",
        "\n",
        "        output_stream = BytesIO()\n",
        "        output.save(output_stream, format='PNG')\n",
        "        output_stream.seek(0)\n",
        "        update.message.reply_photo(photo=output_stream)\n",
        "        print(\"Sent Photo to user\")\n",
        "        update.message.reply_text('Пока! Приятно было пообщаться, если захочешь снова поменять стиль, напиши \"/start\".')\n",
        "        return ConversationHandler.END\n",
        "    else:\n",
        "        update.message.reply_text('Принял первое фото')\n",
        "        first_image_file[chat_id] = image_file\n",
        "        return PHOTO_1\n",
        "    \n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kun7-3Ov51oA"
      },
      "source": [
        "def send_prediction_on_photo_CycleGAN(update, context):\n",
        "    os.chdir('/content/pytorch-CycleGAN-and-pix2pix/')\n",
        "    chat_id = update.message.chat_id\n",
        "    print(\"Got image from {}\".format(chat_id))\n",
        "    update.message.reply_text('Принял зимнюю фотографию, подожди минутку')\n",
        "\n",
        "    os.mkdir(str(chat_id))\n",
        "\n",
        "    image_file = update.message.photo[-1].get_file()\n",
        "    first_image_file[chat_id] = image_file\n",
        "    \n",
        "    image_path = str(chat_id)\n",
        "    first_image_file[chat_id].download(image_path+'/image.png')\n",
        "    del first_image_file[chat_id]\n",
        "\n",
        "    subprocess.call(['python','/content/pytorch-CycleGAN-and-pix2pix/test.py',\n",
        "    '--dataroot',image_path,'--name','winter2summer_yosemite_pretrained','--model','test',\n",
        "    '--no_dropout','--results','/content/'+image_path,'--load_size','720','--crop_size','720'])\n",
        "\n",
        "    shutil.rmtree('/content/pytorch-CycleGAN-and-pix2pix/' + image_path)\n",
        "    \n",
        "    output = Image.open('/content/'+image_path+ '/winter2summer_yosemite_pretrained/test_latest/images/image_fake.png')\n",
        "\n",
        "    output_stream = BytesIO()\n",
        "    output.save(output_stream, format='PNG')\n",
        "    output_stream.seek(0)\n",
        "    update.message.reply_photo(photo=output_stream)\n",
        "\n",
        "    shutil.rmtree('/content/' +image_path)\n",
        "    print(\"Sent Photo to user\")\n",
        "    update.message.reply_text('Пока! Приятно было пообщаться, если захочешь снова поменять стиль, напиши \"/start\".')\n",
        "    return ConversationHandler.END"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Y8h7TWOnVw"
      },
      "source": [
        "def start(update, context):\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
        "    update.message.reply_text('Напиши мне \"/style\", и отправь две картинки .А я перенесу стиль второй картинки на первую')\n",
        "    update.message.reply_text('Напиши мне \"/summer\", и отправь одну зимнюю картинку. Я сделаю её теплее и превращу зиму в лето!)')\n",
        "    update.message.reply_text('Остановить бота - \"/stop\"')\n",
        "    return NEURON_CHOISE"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5f6ubpIrU3h"
      },
      "source": [
        "def cancel(update, context):\n",
        "    update.message.reply_text('Пока! Приятно было пообщаться, если захочешь снова поменять стиль, напиши \"/start\".')\n",
        "\n",
        "    return ConversationHandler.END"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM2WC-60RBAI"
      },
      "source": [
        "NEURON_CHOISE,PHOTO_1,PHOTO_2 = range(3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urm0MZgjM_4D",
        "outputId": "252b54a2-390b-4d05-c032-e62cb9b32074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    token = \"5545169028:AAHBwjySmQu3l2QBkL_jaSmDJoC2jH0gS60\"\n",
        "    # Включим самый базовый логгинг, чтобы видеть сообщения об ошибках\n",
        "    logging.basicConfig(\n",
        "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "        level=logging.INFO)\n",
        "    \n",
        "    updater = Updater(token,use_context=True)\n",
        "    dp = updater.dispatcher\n",
        "\n",
        "    conv_handler = ConversationHandler(\n",
        "        entry_points=[CommandHandler('start', start)],\n",
        "\n",
        "        states={\n",
        "            NEURON_CHOISE: [CommandHandler('style', lambda x,y: PHOTO_1),CommandHandler('summer', lambda x,y: PHOTO_2)],\n",
        "            PHOTO_1: [MessageHandler(Filters.photo, send_prediction_on_photo),],\n",
        "            PHOTO_2: [MessageHandler(Filters.photo, send_prediction_on_photo_CycleGAN),],\n",
        "            \n",
        "        },\n",
        "\n",
        "        fallbacks=[CommandHandler('stop', cancel)]\n",
        "    )\n",
        "\n",
        "    start_button = InlineKeyboardButton('start')\n",
        "    InlineKeyboardMarkup(start_button)\n",
        "    \n",
        "    dp.add_handler(conv_handler)\n",
        "    run_async(conv_handler)\n",
        "    updater.start_polling()\n",
        "\n",
        "    updater.idle()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-24 15:49:56,335 - apscheduler.scheduler - INFO - Scheduler started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got image from 141412337\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 720                           \t[default: 256]\n",
            "                 dataroot: 141412337                     \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 720                           \t[default: 256]\n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: winter2summer_yosemite_pretrained\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: /content/141412337            \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/winter2summer_yosemite_pretrained/latest_net_G.pth\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory /content/141412337/winter2summer_yosemite_pretrained/test_latest\n",
            "processing (0000)-th image... ['141412337/image.png']\n",
            "Sent Photo to user\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-24 15:50:59,714 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
            "2022-07-24 15:50:59,716 - apscheduler.scheduler - INFO - Scheduler has been shut down\n"
          ]
        }
      ]
    }
  ]
}